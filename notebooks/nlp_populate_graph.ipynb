{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "meaning-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import urllib\n",
    "from pprint import pprint\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import wikipedia\n",
    "import spacy\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "\n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-platinum",
   "metadata": {},
   "source": [
    "# Configure spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "powerful-orange",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']\n",
      "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer', 'merge_noun_chunks']\n"
     ]
    }
   ],
   "source": [
    "SUBJECTS = [\"nsubj\", \"nsubjpass\", \"csubj\", \"csubjpass\", \"agent\", \"expl\"]\n",
    "VERBS = ['ROOT', 'advcl']\n",
    "OBJECTS = [\"dobj\", \"dative\", \"attr\", \"oprd\", 'pobj']\n",
    "ENTITY_LABELS = ['PERSON', 'NORP', 'GPE', 'ORG', 'FAC', 'LOC', 'PRODUCT', 'EVENT', 'WORK_OF_ART']\n",
    "\n",
    "api_key = open('.api_key').read()\n",
    "\n",
    "non_nc = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('merge_noun_chunks')\n",
    "\n",
    "print(non_nc.pipe_names)\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-pointer",
   "metadata": {},
   "source": [
    "# Neo4j Connector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tough-jaguar",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None, db=None):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-airport",
   "metadata": {},
   "source": [
    "# Query Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "uniform-cincinnati",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def query_google(query, api_key, limit=10, indent=True, return_lists=True):\n",
    "    \n",
    "    text_ls = []\n",
    "    node_label_ls = []\n",
    "    url_ls = []\n",
    "    \n",
    "    params = {\n",
    "        'query': query,\n",
    "        'limit': limit,\n",
    "        'indent': indent,\n",
    "        'key': api_key,\n",
    "    }   \n",
    "    \n",
    "    service_url = 'https://kgsearch.googleapis.com/v1/entities:search'\n",
    "    url = service_url + '?' + urllib.parse.urlencode(params)\n",
    "    response = json.loads(urllib.request.urlopen(url).read())\n",
    "    \n",
    "    if return_lists:\n",
    "        for element in response['itemListElement']:\n",
    "\n",
    "            try:\n",
    "                node_label_ls.append(element['result']['@type'])\n",
    "            except:\n",
    "                node_label_ls.append('')\n",
    "\n",
    "            try:\n",
    "                text_ls.append(element['result']['detailedDescription']['articleBody'])\n",
    "                #pprint(element['result']['detailedDescription']['articleBody'])\n",
    "            except:\n",
    "                text_ls.append('')\n",
    "                \n",
    "            try:\n",
    "                url_ls.append(element['result']['detailedDescription']['url'])\n",
    "            except:\n",
    "                url_ls.append('')\n",
    "                \n",
    "        return text_ls, node_label_ls, url_ls\n",
    "    \n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-shirt",
   "metadata": {},
   "source": [
    "# NLP Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continuous-contributor",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    \n",
    "    regex = re.compile(r'[\\n\\r\\t]')\n",
    "    clean_text = regex.sub(\" \", text)\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def remove_stop_words_and_punct(text, print_text=False):\n",
    "    \n",
    "    result_ls = []\n",
    "    rsw_doc = non_nc(text)\n",
    "    \n",
    "    for token in rsw_doc:\n",
    "        if print_text:\n",
    "            print(token, token.is_stop)\n",
    "            print('--------------')\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            result_ls.append(str(token))\n",
    "    \n",
    "    result_str = ' '.join(result_ls)\n",
    "\n",
    "    return result_str\n",
    "\n",
    "\n",
    "def create_svo_lists(doc, print_lists=False):\n",
    "    \n",
    "    subject_ls = []\n",
    "    verb_ls = []\n",
    "    object_ls = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ in SUBJECTS:\n",
    "            #print(list(token.ancestors))\n",
    "            subject_ls.append((token.lower_, token.idx))\n",
    "        elif token.dep_ in VERBS:\n",
    "            #print('CHILDREN of ', token.text, ': ' ,list(token.children), token.idx)\n",
    "            verb_ls.append((token.lemma_, token.idx))\n",
    "        elif token.dep_ in OBJECTS:\n",
    "            #print('ANCESTORS of ', token.text, ': ', list(token.ancestors), token.idx)\n",
    "            object_ls.append((token.lower_, token.idx))\n",
    "\n",
    "    if print_lists:\n",
    "        print('SUBJECTS: ', subject_ls)\n",
    "        print('VERBS: ', verb_ls)\n",
    "        print('OBJECTS: ', object_ls)\n",
    "    \n",
    "    return subject_ls, verb_ls, object_ls\n",
    "\n",
    "\n",
    "def remove_duplicates(tup, tup_posn):\n",
    "    \n",
    "    check_val = set()\n",
    "    result = []\n",
    "    \n",
    "    for i in tup:\n",
    "        if i[tup_posn] not in check_val:\n",
    "            result.append(i)\n",
    "            check_val.add(i[tup_posn])\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_dates(tup_ls):\n",
    "    \n",
    "    clean_tup_ls = []\n",
    "    for entry in tup_ls:\n",
    "        if not entry[2].isdigit():\n",
    "            clean_tup_ls.append(entry)\n",
    "    return clean_tup_ls\n",
    "\n",
    "\n",
    "def create_svo_triples(text):\n",
    "    \n",
    "    clean_text = remove_special_characters(text)\n",
    "    doc = nlp(clean_text)\n",
    "    subject_ls, verb_ls, object_ls = create_svo_lists(doc)\n",
    "    \n",
    "    graph_tup_ls = []\n",
    "    dedup_tup_ls = []\n",
    "    clean_tup_ls = []\n",
    "    \n",
    "    for subj in subject_ls: \n",
    "        for obj in object_ls:\n",
    "            \n",
    "            dist_ls = []\n",
    "            \n",
    "            for v in verb_ls:\n",
    "                \n",
    "                # Assemble a list of distances between each object and each verb\n",
    "                dist_ls.append(abs(obj[1] - v[1]))\n",
    "                \n",
    "            # Get the index of the verb with the smallest distance to the object \n",
    "            # and return that verb\n",
    "            index_min = min(range(len(dist_ls)), key=dist_ls.__getitem__)\n",
    "            \n",
    "            # Remve stop words from subjects and objects\n",
    "\n",
    "            no_sw_subj = remove_stop_words_and_punct(subj[0])\n",
    "            no_sw_obj = remove_stop_words_and_punct(obj[0])\n",
    "            \n",
    "            # Add entries to the graph iff neither subject nor object is blank\n",
    "            if no_sw_subj and no_sw_obj:\n",
    "                tup = (no_sw_subj, verb_ls[index_min][0], no_sw_obj)\n",
    "                graph_tup_ls.append(tup)\n",
    "        \n",
    "        #clean_tup_ls = remove_dates(graph_tup_ls)\n",
    "    \n",
    "    dedup_tup_ls = remove_duplicates(graph_tup_ls, 2)\n",
    "    clean_tup_ls = remove_dates(dedup_tup_ls)\n",
    "    \n",
    "    return clean_tup_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-while",
   "metadata": {},
   "source": [
    "# Add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "heard-family",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_verb_edge_string(verb):\n",
    "    \n",
    "    return '[:' + str(verb).upper() + ']'\n",
    "\n",
    "\n",
    "def add_columns(row, limit=1, indent=True):\n",
    "    \n",
    "    params = {\n",
    "        'query': row[2],\n",
    "        'limit': limit,\n",
    "        'indent': indent,\n",
    "        'key': api_key,\n",
    "    } \n",
    "    \n",
    "    service_url = 'https://kgsearch.googleapis.com/v1/entities:search'\n",
    "    url = service_url + '?' + urllib.parse.urlencode(params)\n",
    "    response = json.loads(urllib.request.urlopen(url).read())\n",
    "    \n",
    "    try:\n",
    "        if response['itemListElement'][0]['result']['detailedDescription']['articleBody']:\n",
    "            text = response['itemListElement'][0]['result']['detailedDescription']['articleBody']\n",
    "    except:\n",
    "        text = ' '\n",
    "        \n",
    "    try:\n",
    "        if response['itemListElement'][0]['result']['@type']:\n",
    "            node_labels = response['itemListElement'][0]['result']['@type']\n",
    "    except:\n",
    "        node_labels = ' '\n",
    "\n",
    "    try:\n",
    "        if response['itemListElement'][0]['result']['detailedDescription']['url']:\n",
    "            link = response['itemListElement'][0]['result']['detailedDescription']['url']\n",
    "    except:\n",
    "        link = ' '\n",
    "\n",
    "    row['description'] = text\n",
    "    row['node_labels'] = node_labels\n",
    "    row['url'] = link\n",
    "        \n",
    "    return row\n",
    "\n",
    "\n",
    "def add_df_layer(df):\n",
    "\n",
    "    objects = df['object'].tolist()\n",
    "    final_tup_ls = []\n",
    "\n",
    "    for obj in objects:\n",
    "\n",
    "        text_ls, node_label_ls, url_ls = query_google(obj, api_key, limit=1)\n",
    "\n",
    "        for text in text_ls:\n",
    "            tup = create_svo_triples(text)\n",
    "            dedup_tup = remove_duplicates(tup, 2)\n",
    "            if dedup_tup:\n",
    "                final_tup_ls.extend(dedup_tup)\n",
    "                \n",
    "    new_df = pd.DataFrame(final_tup_ls, columns = ['subject', 'verb', 'object'])\n",
    "    new_df['edge_string'] = new_df['verb'].map(make_verb_edge_string)\n",
    "    new_df = new_df.apply(add_columns, axis=1)\n",
    "    #new_df['text_property'] = new_df['object'].map(add_text)\n",
    "    #new_df['node_labels'] = new_df['object'].map(add_node_labels)\n",
    "    #new_df['url'] = new_df['object'].map(add_url)\n",
    "            \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-works",
   "metadata": {},
   "source": [
    "# Populate the graph from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "mounted-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(rows):\n",
    "    \n",
    "    query = '''\n",
    "    UNWIND $rows AS item\n",
    "    MERGE (s:Subject {name: item.subject})\n",
    "    MERGE (o:Object {name: item.object, description: COALESCE(item.description, 'NOT SET'), url: COALESCE(item.url, 'NOT SET')})\n",
    "    WITH s, o, item\n",
    "    CALL apoc.create.relationship(s, item.edge_string, {}, o)\n",
    "    YIELD rel\n",
    "    RETURN COUNT(s), COUNT(o), COUNT(rel)\n",
    "    '''\n",
    "    \n",
    "    return insert_data(query, rows, batch_size=10000)\n",
    "\n",
    "\n",
    "\n",
    "def insert_data(query, rows, batch_size = 10000):\n",
    "    # Function to handle the updating the Neo4j database in batch mode.\n",
    "\n",
    "    total = 0\n",
    "    batch = 0\n",
    "    start = time.time()\n",
    "    result = None\n",
    "\n",
    "    while batch * batch_size < len(rows):\n",
    "\n",
    "        res = conn.query(query, parameters={'rows': rows[batch*batch_size:(batch+1)*batch_size].to_dict('records')})\n",
    "        if res[0]:\n",
    "            print(res[0])\n",
    "        else:\n",
    "            print(res)\n",
    "        #total += res[0]['total']\n",
    "        batch += 1\n",
    "        #result = {\"total\":total, \"batches\":batch, \"time\":time.time()-start}\n",
    "        result = {'batches': batch, 'time': time.time()-start}\n",
    "        print(result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sixth-malawi",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barack Hussein Obama II (born August 4, 1961) is an American politician and attorney who served as the 44th president of the United States from 2009 to 2017. A member of the Democratic Party, Obama was the first African-American president of the United States. He previously served as a U.S. senator from Illinois from 2005 to 2008 and as an Illinois state senator from 1997 to 2004.\\nObama was born in Honolulu, Hawaii. After graduating from Columbia University in 1983, he worked as a community organizer in Chicago. In 1988, he enrolled in Harvard Law School, where he was the first black person to be president of the Harvard Law Review. After graduating, he became a civil rights attorney and an academic, teaching constitutional law at the University of Chicago Law School from 1992 to 2004. Turning to elective politics, he represented the 13th district from 1997 until 2004 in the Illinois Senate, when he ran for the U.S. Senate. Obama received national attention in 2004 with his March Senate primary win, his well-received July Democratic National Convention keynote address, and his landslide November election to the Senate. In 2008, he was nominated by the Democratic Party for president a year after his presidential campaign began, and after a close primary campaign against Hillary Clinton, Obama was elected over Republican nominee John McCain and was inaugurated alongside his running mate, Joe Biden, on January 20, 2009. Nine months later, he was named the 2009 Nobel Peace Prize laureate.\\nObama signed many landmark bills into law during his first two years in office. The main reforms that were passed include the Affordable Care Act (commonly referred to as ACA or \"Obamacare\"), although without a public health insurance option, the Dodd–Frank Wall Street Reform and Consumer Protection Act, and the Don\\'t Ask, Don\\'t Tell Repeal Act of 2010. The American Recovery and Reinvestment Act of 2009 and Tax Relief, Unemployment Insurance Reauthorization, and Job Creation Act of 2010 served as economic stimuli amidst the Great Recession. After a lengthy debate over the national debt limit, he signed the Budget Control and the American Taxpayer Relief Acts. In foreign policy, he increased U.S. troop levels in Afghanistan, reduced nuclear weapons with the United States–Russia New START treaty, and ended military involvement in the Iraq War. He ordered military involvement in Libya for the implementation of the UN Security Council Resolution 1973, contributing to the overthrow of Muammar Gaddafi. He also ordered the military operations that resulted in the deaths of Osama bin Laden and suspected Yemeni Al-Qaeda operative Anwar al-Awlaki.\\nAfter winning re-election by defeating Republican opponent Mitt Romney, Obama was sworn in for a second term in 2013. During this term, he promoted inclusion for LGBT Americans. His administration filed briefs that urged the Supreme Court to strike down same-sex marriage bans as unconstitutional (United States v. Windsor and Obergefell v. Hodges); same-sex marriage was legalized nationwide in 2015 after the Court ruled so in Obergefell. He advocated for gun control in response to the Sandy Hook Elementary School shooting, indicating support for a ban on assault weapons, and issued wide-ranging executive actions concerning global warming and immigration. In foreign policy, he ordered military intervention in Iraq in response to gains made by ISIL after the 2011 withdrawal from Iraq, continued the process of ending U.S. combat operations in Afghanistan in 2016, promoted discussions that led to the 2015 Paris Agreement on global climate change, initiated sanctions against Russia following the invasion in Ukraine and again after interference in the 2016 U.S. elections, brokered the JCPOA nuclear deal with Iran, and normalized U.S. relations with Cuba. Obama nominated three justices to the Supreme Court: Sonia Sotomayor and Elena Kagan were confirmed as justices, while Merrick Garland faced partisan obstruction from the Republican-led Senate led by Mitch McConnell, which never held hearings or a vote on the nomination. Obama left office in January 2017 and continues to reside in Washington, D.C.During Obama\\'s term in office, the United States\\' reputation abroad, as well as the American economy, significantly improved. Obama\\'s presidency has generally been regarded favorably, and evaluations of his presidency among historians, political scientists, and the general public frequently place him among the upper tier of American presidents.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = wikipedia.summary('barack obama')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "level-pantyhose",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barack hussein obama ii', 'be', 'american politician'),\n",
       " ('barack hussein obama ii', 'be', '44th president'),\n",
       " ('barack hussein obama ii', 'be', 'united states'),\n",
       " ('barack hussein obama ii', 'be', 'democratic party'),\n",
       " ('barack hussein obama ii', 'be', 'african american president')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tup_ls = create_svo_triples(text)  \n",
    "final_tup_ls[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "elementary-campus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 858 ms, sys: 44.4 ms, total: 903 ms\n",
      "Wall time: 12.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "      <th>edge_string</th>\n",
       "      <th>description</th>\n",
       "      <th>node_labels</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barack hussein obama ii</td>\n",
       "      <td>be</td>\n",
       "      <td>american politician</td>\n",
       "      <td>[:BE]</td>\n",
       "      <td></td>\n",
       "      <td>[Thing]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barack hussein obama ii</td>\n",
       "      <td>be</td>\n",
       "      <td>44th president</td>\n",
       "      <td>[:BE]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barack hussein obama ii</td>\n",
       "      <td>be</td>\n",
       "      <td>united states</td>\n",
       "      <td>[:BE]</td>\n",
       "      <td>The United States of America, commonly known a...</td>\n",
       "      <td>[Country, Place, AdministrativeArea, Thing]</td>\n",
       "      <td>https://en.wikipedia.org/wiki/United_States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barack hussein obama ii</td>\n",
       "      <td>be</td>\n",
       "      <td>democratic party</td>\n",
       "      <td>[:BE]</td>\n",
       "      <td>The Democratic Party is one of the two major c...</td>\n",
       "      <td>[Thing, Organization]</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Democratic_Party...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>barack hussein obama ii</td>\n",
       "      <td>be</td>\n",
       "      <td>african american president</td>\n",
       "      <td>[:BE]</td>\n",
       "      <td>The National Museum of African American Histor...</td>\n",
       "      <td>[Place, Museum, CivicStructure, TouristAttract...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/National_Museum_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   subject verb                      object edge_string  \\\n",
       "0  barack hussein obama ii   be         american politician       [:BE]   \n",
       "1  barack hussein obama ii   be              44th president       [:BE]   \n",
       "2  barack hussein obama ii   be               united states       [:BE]   \n",
       "3  barack hussein obama ii   be            democratic party       [:BE]   \n",
       "4  barack hussein obama ii   be  african american president       [:BE]   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  The United States of America, commonly known a...   \n",
       "3  The Democratic Party is one of the two major c...   \n",
       "4  The National Museum of African American Histor...   \n",
       "\n",
       "                                         node_labels  \\\n",
       "0                                            [Thing]   \n",
       "1                                                      \n",
       "2        [Country, Place, AdministrativeArea, Thing]   \n",
       "3                              [Thing, Organization]   \n",
       "4  [Place, Museum, CivicStructure, TouristAttract...   \n",
       "\n",
       "                                                 url  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2        https://en.wikipedia.org/wiki/United_States  \n",
       "3  https://en.wikipedia.org/wiki/Democratic_Party...  \n",
       "4  https://en.wikipedia.org/wiki/National_Museum_...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.DataFrame(final_tup_ls, columns = ['subject', 'verb', 'object'])\n",
    "df['edge_string'] = df['verb'].map(make_verb_edge_string)\n",
    "df = df.apply(add_columns, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "difficult-boating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record COUNT(s)=112 COUNT(o)=112 COUNT(rel)=112>\n",
      "{'batches': 1, 'time': 0.06975555419921875}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batches': 1, 'time': 0.06975555419921875}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = Neo4jConnection(uri=\"bolt://0.0.0.0:7687\", user=\"neo4j\", pwd=\"1234\")\n",
    "conn.query('CREATE CONSTRAINT subj_constraint IF NOT EXISTS ON (s:Subject) ASSERT s.name IS UNIQUE')\n",
    "conn.query('CREATE CONSTRAINT obj_constraint IF NOT EXISTS ON (o:Object) ASSERT o.name IS UNIQUE')\n",
    "create_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "sacred-tobacco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 s, sys: 359 ms, total: 14.6 s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df = add_df_layer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "armed-wisdom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 7)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "important-parking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record COUNT(s)=506 COUNT(o)=506 COUNT(rel)=506>\n",
      "{'batches': 1, 'time': 0.12885475158691406}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batches': 1, 'time': 0.12885475158691406}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_graph(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-export",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-martin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
